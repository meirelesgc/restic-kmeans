{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import urllib.request\n",
    "\n",
    "def download_and_extract_zip(url, dest_folder=\"dataset\"):\n",
    "    zip_filename = url.split(\"/\")[-1]\n",
    "\n",
    "    zip_path = os.path.join(os.getcwd(), zip_filename)\n",
    "\n",
    "    print(f\"Baixando o arquivo de {url}...\")\n",
    "    urllib.request.urlretrieve(url, zip_path)\n",
    "    print(f\"Arquivo baixado para {zip_path}\")\n",
    "\n",
    "    if not os.path.exists(dest_folder):\n",
    "        os.makedirs(dest_folder)\n",
    "        print(f\"Pasta '{dest_folder}' criada.\")\n",
    "\n",
    "    print(f\"Extraindo o arquivo principal para a pasta '{dest_folder}'...\")\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(dest_folder)\n",
    "    print(f\"Arquivo principal extraído com sucesso!\")\n",
    "\n",
    "    os.remove(zip_path)\n",
    "    print(f\"Arquivo ZIP principal removido após extração.\")\n",
    "\n",
    "    nested_zip_path = os.path.join(dest_folder, 'UCI HAR Dataset.zip')\n",
    "\n",
    "    if os.path.exists(nested_zip_path):\n",
    "        print(f\"Arquivo ZIP encontrado dentro da pasta '{dest_folder}': {nested_zip_path}\")\n",
    "        \n",
    "        print(f\"Extraindo o arquivo ZIP dentro da pasta '{dest_folder}'...\")\n",
    "        with zipfile.ZipFile(nested_zip_path, 'r') as nested_zip_ref:\n",
    "            nested_zip_ref.extractall(dest_folder)\n",
    "        print(f\"Arquivo extraído com sucesso!\")\n",
    "\n",
    "        os.remove(nested_zip_path)\n",
    "        print(f\"Arquivo ZIP interno removido após extração.\")\n",
    "    else:\n",
    "        print(f\"Nenhum arquivo 'UCI HAR Dataset.zip' encontrado dentro de '{dest_folder}'.\")\n",
    "\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/static/public/240/human+activity+recognition+using+smartphones.zip\"\n",
    "download_and_extract_zip(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataset/UCI HAR Dataset.names\n",
    "\n",
    "O dataset contém 561 features por amostra, extraídas de dados de aceleração e giroscópio.\n",
    "Cada amostra possui um rótulo de atividade associado.\n",
    "Os dados já estão divididos em train e test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar as features\n",
    "features = pd.read_csv('dataset/UCI HAR Dataset/features.txt', sep=r'\\s+', header=None)\n",
    "\n",
    "# Carregar os dados de treinamento\n",
    "X_train = pd.read_csv('dataset/UCI HAR Dataset/train/X_train.txt', sep=r'\\s+', header=None)\n",
    "y_train = pd.read_csv('dataset/UCI HAR Dataset/train/y_train.txt', sep=r'\\s+', header=None)\n",
    "\n",
    "# Carregar os dados de teste\n",
    "X_test = pd.read_csv('dataset/UCI HAR Dataset/test/X_test.txt', sep=r'\\s+', header=None)\n",
    "y_test = pd.read_csv('dataset/UCI HAR Dataset/test/y_test.txt', sep=r'\\s+', header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escale os dados para normalizar as magnitudes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reduzindo a dimensionalidade usando PCA (para facilitar a visualização)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)  # Reduza para 2 dimensões\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X_train_pca[:, 0], X_train_pca[:, 1], s=5, alpha=0.7, cmap='viridis')\n",
    "plt.title('Dados Originais em 2D (PCA)')\n",
    "plt.xlabel('Componente Principal 1')\n",
    "plt.ylabel('Componente Principal 2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inertia = []\n",
    "k_values = range(1, 11)\n",
    "\n",
    "for k in k_values:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(X_train_scaled)\n",
    "    inertia.append(kmeans.inertia_)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(k_values, inertia, marker='o')\n",
    "plt.title('Método do Cotovelo')\n",
    "plt.xlabel('Número de Clusters (k)')\n",
    "plt.ylabel('Inércia')\n",
    "plt.xticks(k_values)\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escolhendo o número de clusters (6 para as 6 atividades):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=6, random_state=42)\n",
    "kmeans.fit(X_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = kmeans.predict(X_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X_train_pca[:, 0], X_train_pca[:, 1], c=clusters, cmap='viridis', s=5)\n",
    "plt.title('Clusters Identificados pelo K-Means')\n",
    "plt.xlabel('Componente Principal 1')\n",
    "plt.ylabel('Componente Principal 2')\n",
    "plt.colorbar(label='Cluster')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X_train_pca[:, 0], X_train_pca[:, 1], c=y_train.values.ravel(), cmap='tab10', s=5)\n",
    "plt.title('Agrupamento Real (Baseado nos Rótulos)')\n",
    "plt.xlabel('Componente Principal 1')\n",
    "plt.ylabel('Componente Principal 2')\n",
    "plt.colorbar(label='Atividade')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_train_pca[:, 0], X_train_pca[:, 1], c=clusters, cmap='viridis', s=5)\n",
    "plt.title('Clusters gerados pelo K-Means')\n",
    "plt.xlabel('Componente Principal 1')\n",
    "plt.ylabel('Componente Principal 2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=6, random_state=42, max_iter=300, n_init=10, verbose=1)\n",
    "kmeans.fit(X_train_scaled)\n",
    "\n",
    "centers = kmeans.cluster_centers_\n",
    "if X_train_scaled.shape[1] > 2:\n",
    "    centers_pca = pca.transform(centers)\n",
    "else:\n",
    "    centers_pca = centers\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X_train_pca[:, 0], X_train_pca[:, 1], c=clusters, cmap='viridis', s=5, alpha=0.7)\n",
    "plt.scatter(centers_pca[:, 0], centers_pca[:, 1], c='red', marker='X', s=200, label='Centros')\n",
    "plt.title('Centros dos Clusters')\n",
    "plt.xlabel('Componente Principal 1')\n",
    "plt.ylabel('Componente Principal 2')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import adjusted_rand_score\n",
    "\n",
    "ari = adjusted_rand_score(y_train.values.ravel(), clusters)\n",
    "print(f'Adjusted Rand Index: {ari}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "score = silhouette_score(X_train_scaled, clusters)\n",
    "print(f'Silhouette Score: {score}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
